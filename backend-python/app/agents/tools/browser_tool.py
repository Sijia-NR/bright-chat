"""
æµè§ˆå™¨å·¥å…·ï¼ˆæœåŠ¡ç«¯ Playwright æ— å¤´æ¨¡å¼ï¼‰
Browser Tool using Server-Side Playwright Headless Mode

å…è®¸ Agent æ‰§è¡Œç½‘é¡µæµè§ˆã€æ•°æ®æŠ“å–ç­‰ä»»åŠ¡
Allows Agent to perform web browsing, data scraping, etc.
"""
import asyncio
import logging
from typing import Dict, Any, Optional, List
from urllib.parse import unquote
from playwright.async_api import async_playwright, Browser, Page, BrowserContext

logger = logging.getLogger(__name__)

# å…¨å±€æµè§ˆå™¨å®ä¾‹ï¼ˆå¤ç”¨ä»¥æé«˜æ€§èƒ½ï¼‰
_browser: Optional[Browser] = None
_context: Optional[BrowserContext] = None
_playwright = None

# å¹¶å‘ä¿æŠ¤é”
_browser_lock = asyncio.Lock()
_context_lock = asyncio.Lock()


async def _get_browser() -> Browser:
    """è·å–æˆ–åˆ›å»ºæµè§ˆå™¨å®ä¾‹ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    global _browser, _playwright

    async with _browser_lock:
        if _browser is None or not _browser.is_connected():
            logger.info("ğŸŒ [æµè§ˆå™¨å·¥å…·] å¯åŠ¨æ— å¤´æµè§ˆå™¨...")
            _playwright = await async_playwright().start()
            _browser = await _playwright.chromium.launch(headless=True)
            logger.info("âœ… [æµè§ˆå™¨å·¥å…·] æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")

        return _browser


async def _get_context() -> BrowserContext:
    """è·å–æˆ–åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    global _context

    browser = await _get_browser()

    async with _context_lock:
        if _context is None or not _browser.is_connected():
            logger.info("ğŸŒ [æµè§ˆå™¨å·¥å…·] åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡...")
            _context = await browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            )
            logger.info("âœ… [æµè§ˆå™¨å·¥å…·] æµè§ˆå™¨ä¸Šä¸‹æ–‡åˆ›å»ºæˆåŠŸ")

        return _context


async def browser_tool(
    action: str,
    url: Optional[str] = None,
    selector: Optional[str] = None,
    text: Optional[str] = None,
    wait_time: int = 3000
) -> Dict[str, Any]:
    """
    æµè§ˆå™¨å·¥å…·ï¼ˆæœåŠ¡ç«¯æ— å¤´æ¨¡å¼ï¼‰

    æ”¯æŒçš„æ“ä½œï¼š
    - navigate: å¯¼èˆªåˆ° URL
    - screenshot: æˆªå›¾
    - click: ç‚¹å‡»å…ƒç´ 
    - fill: å¡«å†™è¡¨å•
    - scrape: æŠ“å–é¡µé¢æ–‡æœ¬
    - search: æœç´¢å¼•æ“æœç´¢

    Args:
        action: æ“ä½œç±»å‹ (navigate/screenshot/click/fill/scrape/search)
        url: ç›®æ ‡ URL
        selector: CSS é€‰æ‹©å™¨
        text: æ–‡æœ¬å†…å®¹ï¼ˆç”¨äºå¡«å†™æˆ–æœç´¢ï¼‰
        wait_time: ç­‰å¾…æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰

    Returns:
        æ“ä½œç»“æœ
    """
    import time
    start_time = time.time()

    logger.info(f"ğŸŒ [æµè§ˆå™¨å·¥å…·] å¼€å§‹æ‰§è¡Œæ“ä½œ: {action}")
    logger.info(f"ğŸŒ [æµè§ˆå™¨å·¥å…·] URL: {url}")
    logger.info(f"ğŸŒ [æµè§ˆå™¨å·¥å…·] é€‰æ‹©å™¨: {selector}")

    try:
        browser = await _get_browser()
        context = await _get_context()
        page = await context.new_page()

        result = {"success": False, "data": None, "error": None}

        if action == "navigate":
            # å¯¼èˆªåˆ°æŒ‡å®š URL
            if not url:
                result["error"] = "ç¼ºå°‘ URL å‚æ•°"
                return result

            logger.info(f"ğŸŒ [æµè§ˆå™¨å·¥å…·] å¯¼èˆªåˆ°: {url}")
            await page.goto(url, wait_until="networkidle", timeout=30000)
            result["success"] = True
            result["data"] = {"url": page.url, "title": await page.title()}

        elif action == "screenshot":
            # æˆªå›¾
            screenshot_bytes = await page.screenshot(full_page=False)
            import base64
            result["success"] = True
            result["data"] = {
                "screenshot": base64.b64encode(screenshot_bytes).decode('utf-8'),
                "format": "base64"
            }

        elif action == "click":
            # ç‚¹å‡»å…ƒç´ 
            if not selector:
                result["error"] = "ç¼ºå°‘ selector å‚æ•°"
                return result

            logger.info(f"ğŸŒ [æµè§ˆå™¨å·¥å…·] ç‚¹å‡»å…ƒç´ : {selector}")
            await page.click(selector, timeout=10000)
            await page.wait_for_timeout(wait_time)
            result["success"] = True
            result["data"] = {"clicked": selector}

        elif action == "fill":
            # å¡«å†™è¡¨å•
            if not selector or not text:
                result["error"] = "ç¼ºå°‘ selector æˆ– text å‚æ•°"
                return result

            logger.info(f"ğŸŒ [æµè§ˆå™¨å·¥å…·] å¡«å†™: {selector} = {text}")
            await page.fill(selector, text, timeout=10000)
            result["success"] = True
            result["data"] = {"filled": selector, "text": text}

        elif action == "scrape":
            # æŠ“å–é¡µé¢æ–‡æœ¬
            if url:
                await page.goto(url, wait_until="networkidle", timeout=30000)

            # ç­‰å¾…é¡µé¢åŠ è½½
            await page.wait_for_timeout(2000)

            # è·å–é¡µé¢æ–‡æœ¬
            text_content = await page.inner_text("body")

            # è·å–é¡µé¢å…ƒæ•°æ®
            title = await page.title()
            url_final = page.url

            result["success"] = True
            result["data"] = {
                "title": title,
                "url": url_final,
                "content": text_content[:10000],  # é™åˆ¶é•¿åº¦
                "content_length": len(text_content)
            }

        elif action == "search":
            # æœç´¢å¼•æ“æœç´¢ï¼ˆä½¿ç”¨ç™¾åº¦ï¼‰
            if not text:
                result["error"] = "ç¼ºå°‘æœç´¢å…³é”®è¯"
                return result

            # âœ… æ”¹ä¸ºç™¾åº¦æœç´¢
            search_url = f"https://www.baidu.com/s?wd={text}"
            logger.info(f"ğŸŒ [æµè§ˆå™¨å·¥å…·] ç™¾åº¦æœç´¢: {text}")

            await page.goto(search_url, wait_until="networkidle", timeout=30000)
            await page.wait_for_timeout(2000)

            # æå–ç™¾åº¦æœç´¢ç»“æœ
            # ç™¾åº¦ç»“æœé€‰æ‹©å™¨ï¼šdiv.c-container æˆ– div.result
            results = await page.query_selector_all("div.c-container")

            search_data = []
            for i, result_elem in enumerate(results[:10]):  # æœ€å¤š 10 ä¸ªç»“æœ
                try:
                    # ç™¾åº¦çš„æ ‡é¢˜é€‰æ‹©å™¨
                    title_elem = await result_elem.query_selector("h3 a")
                    if not title_elem:
                        continue

                    title = await title_elem.inner_text()
                    link = await title_elem.get_attribute("href")

                    # ç™¾åº¦çš„æ‘˜è¦é€‰æ‹©å™¨
                    snippet_elem = await result_elem.query_selector("div.c-abstract")
                    snippet = await snippet_elem.inner_text() if snippet_elem else ""

                    # æ¸…ç†ç™¾åº¦é“¾æ¥ï¼ˆå»é™¤ç™¾åº¦è·³è½¬é“¾æ¥ï¼‰
                    if link and link.startswith("/link?url="):
                        # è§£ç ç™¾åº¦è·³è½¬é“¾æ¥
                        link = unquote(link.split("url=")[1].split("&")[0])

                    search_data.append({
                        "rank": i + 1,
                        "title": title.strip(),
                        "url": link,
                        "snippet": snippet[:200] if snippet else ""
                    })
                except Exception as e:
                    logger.warning(f"âš ï¸ [æµè§ˆå™¨å·¥å…·] æå–ç™¾åº¦ç»“æœ {i+1} å¤±è´¥: {e}")
                    continue

            result["success"] = True
            result["data"] = {
                "query": text,
                "results": search_data,
                "count": len(search_data),
                "engine": "baidu"  # æ ‡è®°ä½¿ç”¨çš„æœç´¢å¼•æ“
            }
            logger.info(f"âœ… [æµè§ˆå™¨å·¥å…·] ç™¾åº¦æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(search_data)} ä¸ªç»“æœ")

        else:
            result["error"] = f"ä¸æ”¯æŒçš„æ“ä½œ: {action}"

        # å…³é—­é¡µé¢
        await page.close()

        execution_time = time.time() - start_time
        logger.info(f"âœ… [æµè§ˆå™¨å·¥å…·] æ“ä½œå®Œæˆï¼Œè€—æ—¶: {execution_time:.3f}ç§’")

        return result

    except Exception as e:
        error_msg = f"æµè§ˆå™¨æ“ä½œå¤±è´¥: {str(e)}"
        logger.error(f"âŒ [æµè§ˆå™¨å·¥å…·] {error_msg}")
        return {"success": False, "error": error_msg, "data": None}


async def close_browser():
    """å…³é—­æµè§ˆå™¨ï¼ˆç”¨äºæ¸…ç†ï¼‰"""
    global _browser, _context, _playwright

    async with _context_lock:
        if _context:
            await _context.close()
            _context = None

    async with _browser_lock:
        if _browser:
            await _browser.close()
            _browser = None

        if _playwright:
            await _playwright.stop()
            _playwright = None

    logger.info("ğŸŒ [æµè§ˆå™¨å·¥å…·] æµè§ˆå™¨å·²å…³é—­")
