#!/usr/bin/env python3
"""
Minimal API for Bright-Chat - Single file implementation
"""
import os
import sys
import base64
from datetime import datetime, timedelta
from typing import Optional, List
from enum import Enum
from pydantic import BaseModel
from fastapi import FastAPI, HTTPException, Depends, status, Header, UploadFile, File, BackgroundTasks
from fastapi.responses import StreamingResponse
import asyncio
import json
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy import create_engine, Column, String, DateTime, Boolean, Enum as SQLEnum, Text, ForeignKey, UniqueConstraint, Integer, JSON, text
from sqlalchemy.sql import func
from sqlalchemy.orm import sessionmaker, Session, relationship
from sqlalchemy.ext.declarative import declarative_base
from jose import JWTError, jwt
import hashlib
import uuid
import secrets
import time
import logging
import httpx
from pathlib import Path

# Configure logging - restore INFO level for detailed logs
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Restore httpx and uvicorn access logs to INFO
logging.getLogger("httpx").setLevel(logging.INFO)
logging.getLogger("uvicorn.access").setLevel(logging.INFO)

# RAG ç›¸å…³å¯¼å…¥
from app.rag.config import get_rag_config, KNOWLEDGE_COLLECTION
from app.rag.document_processor import DocumentProcessor

# Agent ç›¸å…³å¯¼å…¥
from app.agents.router import router as agents_router

# é…ç½®ç®¡ç† - ä½¿ç”¨ Settings è€Œéç¡¬ç¼–ç 
from app.core.config import settings

# Database setup - ä»ç¯å¢ƒå˜é‡è¯»å–
DATABASE_URL = settings.DATABASE_URL
engine = create_engine(DATABASE_URL, pool_pre_ping=True)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

# Password hashing
import bcrypt

def hash_password(password: str) -> str:
    """Hash password using bcrypt"""
    pwd_bytes = password.encode('utf-8')
    salt = bcrypt.gensalt()
    hashed_password = bcrypt.hashpw(pwd_bytes, salt)
    return hashed_password.decode('utf-8')

def verify_password(plain_password: str, hashed_password: str) -> bool:
    """Verify password against hash (supports both bcrypt and SHA256)"""
    # Try bcrypt first
    if hashed_password.startswith('$2b$') or hashed_password.startswith('$2a$'):
        try:
            return bcrypt.checkpw(plain_password.encode('utf-8'), hashed_password.encode('utf-8'))
        except Exception:
            pass

    # Fallback to SHA256 for backwards compatibility
    return hashlib.sha256(plain_password.encode()).hexdigest() == hashed_password

# JWT settings - ä»ç¯å¢ƒå˜é‡è¯»å–
SECRET_KEY = settings.JWT_SECRET_KEY
ALGORITHM = settings.JWT_ALGORITHM
ACCESS_TOKEN_EXPIRE_MINUTES = settings.JWT_ACCESS_TOKEN_EXPIRE_MINUTES

# App settings - ä» Settings è¯»å–ï¼Œä¸ä½¿ç”¨ç¡¬ç¼–ç 
APP_NAME = settings.APP_NAME
API_PREFIX = settings.API_PREFIX
SERVER_HOST = settings.SERVER_HOST
SERVER_PORT = settings.SERVER_PORT

# IAS settings - MockServer configuration
IAS_BASE_URL = "http://localhost:18063"
IAS_APP_KEY = "APP_KEY"

# Models
class UserRole(str, Enum):
    ADMIN = "admin"
    USER = "user"

class User(Base):
    __tablename__ = "users"
    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    username = Column(String(50), unique=True, nullable=False, index=True)
    password_hash = Column(String(255), nullable=False)
    role = Column(SQLEnum(UserRole), nullable=False, default=UserRole.USER)
    is_active = Column(Boolean, default=True)
    created_at = Column(DateTime, nullable=False, default=func.now())
    updated_at = Column(DateTime, nullable=False, default=func.now(), onupdate=func.now())

class Session(Base):
    __tablename__ = "sessions"
    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    title = Column(String(200), nullable=False)
    user_id = Column(String(36), nullable=False, index=True)
    agent_id = Column(String(36), nullable=True, index=True)  # æ–°å¢ï¼šå…³è”çš„ Agent ID
    last_updated = Column(DateTime, nullable=False, default=func.now(), onupdate=func.now())
    created_at = Column(DateTime, nullable=False, default=func.now())

class Message(Base):
    __tablename__ = "messages"
    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    session_id = Column(String(36), nullable=False, index=True)
    role = Column(String(20), nullable=False)
    content = Column(String(5000), nullable=False)
    timestamp = Column(DateTime, nullable=False, default=func.now())

class MessageFavorite(Base):
    """æ¶ˆæ¯æ”¶è—è¡¨"""
    __tablename__ = "message_favorites"

    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    user_id = Column(String(36), ForeignKey("users.id"), nullable=False, index=True)
    message_id = Column(String(36), ForeignKey("messages.id"), nullable=False, index=True)
    session_id = Column(String(36), ForeignKey("sessions.id"), nullable=False, index=True)
    note = Column(String(500), nullable=True)  # ç”¨æˆ·å¤‡æ³¨
    created_at = Column(DateTime, nullable=False, default=func.now())

    # å”¯ä¸€çº¦æŸï¼šä¸€ä¸ªç”¨æˆ·å¯¹ä¸€æ¡æ¶ˆæ¯åªèƒ½æ”¶è—ä¸€æ¬¡
    __table_args__ = (
        UniqueConstraint('user_id', 'message_id', name='uq_user_message'),
    )

    # Relationships
    user = relationship("User")
    message = relationship("Message")
    session = relationship("Session")

class LLMModelType(str, Enum):
    OPENAI = "openai"
    ANTHROPIC = "anthropic"
    CUSTOM = "custom"
    IAS = "ias"

class LLMModel(Base):
    """LLM æ¨¡å‹é…ç½®è¡¨"""
    __tablename__ = "llm_models"

    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    name = Column(String(100), unique=True, nullable=False, index=True)
    display_name = Column(String(100), nullable=False)
    model_type = Column(SQLEnum(LLMModelType), nullable=False, default=LLMModelType.CUSTOM)
    api_url = Column(String(500), nullable=False)
    api_key = Column(Text, nullable=False)  # æ˜æ–‡å­˜å‚¨ API Keyï¼Œadmin ç”¨æˆ·å¯è§
    api_version = Column(String(50), nullable=True)
    description = Column(Text, nullable=True)
    is_active = Column(Boolean, default=True, index=True)
    max_tokens = Column(Integer, default=4096)
    temperature = Column(Integer, default=70)  # å­˜å‚¨ä¸º 70 è¡¨ç¤º 0.70
    stream_supported = Column(Boolean, default=True)
    custom_headers = Column(JSON, nullable=True)
    created_at = Column(DateTime, nullable=False, default=func.now())
    updated_at = Column(DateTime, nullable=False, default=func.now(), onupdate=func.now())
    created_by = Column(String(36), ForeignKey("users.id"), nullable=True)

    # Relationships
    creator = relationship("User")

# ==================== Knowledge Base Models ====================

class KnowledgeGroup(Base):
    """çŸ¥è¯†åº“åˆ†ç»„è¡¨"""
    __tablename__ = "knowledge_groups"
    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    name = Column(String(100), nullable=False)
    user_id = Column(String(36), ForeignKey("users.id"), nullable=False)
    description = Column(Text, nullable=True)
    created_at = Column(DateTime, nullable=False, default=func.now())
    updated_at = Column(DateTime, nullable=False, default=func.now(), onupdate=func.now())

    # Relationships
    user = relationship("User")
    knowledge_bases = relationship("KnowledgeBase", back_populates="group", cascade="all, delete-orphan")

class KnowledgeBase(Base):
    """çŸ¥è¯†åº“è¡¨"""
    __tablename__ = "knowledge_bases"
    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    group_id = Column(String(36), ForeignKey("knowledge_groups.id"), nullable=True)  # å…è®¸ä¸ºç©ºï¼Œæ”¯æŒç‹¬ç«‹çŸ¥è¯†åº“
    user_id = Column(String(36), ForeignKey("users.id"), nullable=False)
    name = Column(String(200), nullable=False)
    description = Column(Text, nullable=True)
    embedding_model = Column(String(100), default="bge-large-zh-v1.5")
    chunk_size = Column(Integer, default=500)
    chunk_overlap = Column(Integer, default=50)
    created_at = Column(DateTime, nullable=False, default=func.now())
    updated_at = Column(DateTime, nullable=False, default=func.now(), onupdate=func.now())

    # Relationships
    user = relationship("User")
    group = relationship("KnowledgeGroup", back_populates="knowledge_bases")
    documents = relationship("Document", back_populates="knowledge_base", cascade="all, delete-orphan")

class Document(Base):
    """æ–‡æ¡£è¡¨"""
    __tablename__ = "documents"
    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    knowledge_base_id = Column(String(36), ForeignKey("knowledge_bases.id"), nullable=False)
    filename = Column(String(255), nullable=False)
    file_type = Column(String(255), nullable=False)
    file_size = Column(Integer, nullable=False)
    upload_status = Column(String(50), default="pending")  # pending, processing, completed, error
    chunk_count = Column(Integer, default=0)
    error_message = Column(Text, nullable=True)
    processed_at = Column(DateTime, nullable=True)
    created_at = Column(DateTime, nullable=False, default=func.now())
    updated_at = Column(DateTime, nullable=False, default=func.now(), onupdate=func.now())

    # Relationships
    knowledge_base = relationship("KnowledgeBase", back_populates="documents")

# Pydantic models
class UserCreate(BaseModel):
    username: str
    password: str
    role: UserRole = UserRole.USER

class UserUpdate(BaseModel):
    username: Optional[str] = None
    role: Optional[UserRole] = None

class UserResponse(BaseModel):
    id: str
    username: str
    role: str
    created_at: datetime

    class Config:
        from_attributes = True

class LoginRequest(BaseModel):
    username: str
    password: str

class LoginResponse(BaseModel):
    id: str
    username: str
    role: str
    created_at: datetime
    token: str

class SessionCreate(BaseModel):
    title: str
    user_id: str
    agent_id: Optional[str] = None  # æ–°å¢ï¼šå…³è”çš„ Agent ID

class SessionResponse(BaseModel):
    id: str
    title: str
    last_updated: datetime
    user_id: str
    agent_id: Optional[str] = None  # æ–°å¢ï¼šå…³è”çš„ Agent ID

    class Config:
        from_attributes = True

class MessageCreate(BaseModel):
    messages: List[dict]

class MessageResponse(BaseModel):
    id: str
    role: str
    content: str
    timestamp: datetime

    class Config:
        from_attributes = True

# Favorite Pydantic models
class FavoriteCreate(BaseModel):
    """åˆ›å»ºæ”¶è—è¯·æ±‚"""
    note: Optional[str] = None

class FavoriteResponse(BaseModel):
    """æ”¶è—å“åº”"""
    id: str
    message: MessageResponse
    session: SessionResponse
    note: Optional[str]
    created_at: datetime

    class Config:
        from_attributes = True

class FavoriteListResponse(BaseModel):
    """æ”¶è—åˆ—è¡¨å“åº”"""
    favorites: List[FavoriteResponse]
    total: int

class FavoriteStatusResponse(BaseModel):
    """æ”¶è—çŠ¶æ€å“åº”"""
    is_favorited: bool
    favorite_id: Optional[str] = None

# LLM Model Pydantic models
class LLMModelCreate(BaseModel):
    """åˆ›å»º LLM æ¨¡å‹è¯·æ±‚"""
    name: str
    display_name: str
    model_type: LLMModelType = LLMModelType.CUSTOM
    api_url: str
    api_key: str  # Will be encrypted before storage
    api_version: Optional[str] = None
    description: Optional[str] = None
    is_active: bool = True
    max_tokens: int = 4096
    temperature: float = 0.70
    stream_supported: bool = True
    custom_headers: Optional[dict] = None

class LLMModelUpdate(BaseModel):
    """æ›´æ–° LLM æ¨¡å‹è¯·æ±‚"""
    display_name: Optional[str] = None
    api_url: Optional[str] = None
    api_key: Optional[str] = None
    api_version: Optional[str] = None
    description: Optional[str] = None
    is_active: Optional[bool] = None
    max_tokens: Optional[int] = None
    temperature: Optional[float] = None
    stream_supported: Optional[bool] = None
    custom_headers: Optional[dict] = None

class LLMModelResponse(BaseModel):
    """LLM æ¨¡å‹å“åº”"""
    id: str
    name: str
    display_name: str
    model_type: str
    api_url: str
    api_version: Optional[str]
    description: Optional[str]
    is_active: bool
    max_tokens: int
    temperature: float
    stream_supported: bool
    created_at: datetime

    class Config:
        from_attributes = True

class LLMModelListResponse(BaseModel):
    """LLM æ¨¡å‹åˆ—è¡¨å“åº”"""
    models: List[LLMModelResponse]
    total: int

# Knowledge Base Pydantic models
class KnowledgeGroupCreate(BaseModel):
    """åˆ›å»ºçŸ¥è¯†åº“åˆ†ç»„è¯·æ±‚"""
    name: str
    description: Optional[str] = None

class KnowledgeGroupResponse(BaseModel):
    """çŸ¥è¯†åº“åˆ†ç»„å“åº”"""
    id: str
    name: str
    user_id: str
    description: Optional[str] = None
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True

class KnowledgeBaseCreate(BaseModel):
    """åˆ›å»ºçŸ¥è¯†åº“è¯·æ±‚"""
    group_id: Optional[str] = None  # å…è®¸ä¸æŒ‡å®šåˆ†ç»„ï¼Œåˆ›å»ºç‹¬ç«‹çŸ¥è¯†åº“
    name: str
    description: Optional[str] = None
    embedding_model: str = "bge-large-zh-v1.5"
    chunk_size: int = 500
    chunk_overlap: int = 50

class KnowledgeBaseResponse(BaseModel):
    """çŸ¥è¯†åº“å“åº”"""
    id: str
    group_id: Optional[str] = None
    user_id: str
    name: str
    description: Optional[str] = None
    embedding_model: str
    chunk_size: int
    chunk_overlap: int
    created_at: datetime
    updated_at: datetime
    document_count: Optional[int] = 0

    class Config:
        from_attributes = True

class DocumentResponse(BaseModel):
    """æ–‡æ¡£å“åº”"""
    id: str
    knowledge_base_id: str
    filename: str
    file_type: str
    file_size: int
    upload_status: str
    chunk_count: int
    error_message: Optional[str] = None
    processed_at: Optional[datetime] = None
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True

# Utilities
# This function is now defined above

def get_password_hash(password: str) -> str:
    return hash_password(password)

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

def get_user_by_username(db: Session, username: str) -> Optional[User]:
    return db.query(User).filter(User.username == username).first()

def get_user_by_id(db: Session, user_id: str) -> Optional[User]:
    return db.query(User).filter(User.id == user_id).first()

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# JWT Authentication dependency
async def get_current_user(authorization: Optional[str] = Header(None), db: Session = Depends(get_db)) -> User:
    """ä» JWT token è·å–å½“å‰ç”¨æˆ·"""
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )

    # æå– Bearer token
    if authorization is None:
        raise credentials_exception

    if not authorization.startswith("Bearer "):
        raise credentials_exception

    token = authorization[7:]  # å»æ‰ "Bearer " å‰ç¼€

    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id: str = payload.get("sub")
        if user_id is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception

    user = get_user_by_id(db, user_id)
    if user is None:
        raise credentials_exception
    return user

# Model configuration service functions
def create_llm_model(db: Session, model_data: LLMModelCreate, creator_id: str) -> LLMModel:
    """åˆ›å»ºæ–°çš„ LLM æ¨¡å‹é…ç½®"""
    # æ£€æŸ¥åç§°æ˜¯å¦å·²å­˜åœ¨
    existing = db.query(LLMModel).filter(LLMModel.name == model_data.name).first()
    if existing:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=f"Model with name '{model_data.name}' already exists"
        )

    # åˆ›å»ºæ¨¡å‹
    db_model = LLMModel(
        name=model_data.name,
        display_name=model_data.display_name,
        model_type=model_data.model_type,
        api_url=model_data.api_url,
        api_key=model_data.api_key,  # æ˜æ–‡å­˜å‚¨
        api_version=model_data.api_version,
        description=model_data.description,
        is_active=model_data.is_active,
        max_tokens=model_data.max_tokens,
        temperature=int(model_data.temperature * 100),  # è½¬æ¢ä¸ºæ•´æ•°
        stream_supported=model_data.stream_supported,
        custom_headers=model_data.custom_headers,
        created_by=creator_id
    )

    db.add(db_model)
    db.commit()
    db.refresh(db_model)
    return db_model

def get_llm_model(db: Session, model_id: str) -> Optional[LLMModel]:
    """è·å–æ¨¡å‹"""
    return db.query(LLMModel).filter(LLMModel.id == model_id).first()

def get_llm_model_by_name(db: Session, name: str) -> Optional[LLMModel]:
    """æ ¹æ®åç§°è·å–æ¨¡å‹"""
    return db.query(LLMModel).filter(LLMModel.name == name).first()

def get_active_llm_models(db: Session) -> List[LLMModel]:
    """è·å–æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹"""
    return db.query(LLMModel).filter(LLMModel.is_active == True).order_by(LLMModel.created_at.desc()).all()

def list_llm_models(db: Session, skip: int = 0, limit: int = 100) -> List[LLMModel]:
    """åˆ—å‡ºæ‰€æœ‰æ¨¡å‹ï¼ˆç®¡ç†å‘˜ï¼‰"""
    return db.query(LLMModel).offset(skip).limit(limit).all()

def update_llm_model(db: Session, model_id: str, model_data: LLMModelUpdate) -> Optional[LLMModel]:
    """æ›´æ–°æ¨¡å‹é…ç½®"""
    db_model = get_llm_model(db, model_id)
    if not db_model:
        return None

    # æ›´æ–°å­—æ®µ
    for field, value in model_data.model_dump(exclude_unset=True).items():
        if field == 'api_key' and value:
            # æ˜æ–‡å­˜å‚¨ API Key
            setattr(db_model, 'api_key', value)
        elif field == 'temperature' and value is not None:
            # è½¬æ¢ä¸ºæ•´æ•°
            setattr(db_model, field, int(value * 100))
        else:
            setattr(db_model, field, value)

    db.commit()
    db.refresh(db_model)
    return db_model

def delete_llm_model(db: Session, model_id: str) -> bool:
    """åˆ é™¤æ¨¡å‹é…ç½®"""
    db_model = get_llm_model(db, model_id)
    if not db_model:
        return False

    db.delete(db_model)
    db.commit()
    return True

def require_admin(current_user: User = Depends(get_current_user)):
    """è¦æ±‚ç®¡ç†å‘˜æƒé™çš„ä¾èµ–"""
    if current_user.role != UserRole.ADMIN:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Admin access required"
        )
    return current_user

# Initialize database
Base.metadata.create_all(bind=engine)

# Create FastAPI app
app = FastAPI(
    title="Bright-Chat API",
    description="Bright-Chat Backend API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# åˆ›å»ºä¸Šä¼ ç›®å½•
UPLOAD_DIR = Path("uploads/documents")
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
logger.info(f"ä¸Šä¼ ç›®å½•å·²åˆ›å»º/ç¡®è®¤: {UPLOAD_DIR}")

# CORS middleware - å…è®¸æ‰€æœ‰æ¥æºè®¿é—®ï¼ˆæ”¯æŒå±€åŸŸç½‘ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æº
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Mount Agent router
app.include_router(agents_router, prefix=f"{API_PREFIX}/agents", tags=["agents"])
logger.info("Agent routes mounted at /api/v1/agents")

# Auth endpoints
@app.post(f"{API_PREFIX}/auth/login", response_model=LoginResponse)
async def login(login_data: LoginRequest, db: Session = Depends(get_db)):
    user = get_user_by_username(db, login_data.username)
    if not user or not verify_password(login_data.password, user.password_hash):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect username or password",
            headers={"WWW-Authenticate": "Bearer"},
        )

    access_token_expires = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = create_access_token(
        data={"sub": user.id}, expires_delta=access_token_expires
    )

    return LoginResponse(
        id=user.id,
        username=user.username,
        role=user.role.value,
        created_at=user.created_at,
        token=access_token
    )

@app.post(f"{API_PREFIX}/auth/logout")
async def logout():
    # In a real implementation, we would add the token to a blacklist
    # or perform other cleanup operations
    return {"message": "Successfully logged out"}

# Admin user management
@app.get(f"{API_PREFIX}/admin/users", response_model=List[UserResponse])
async def get_users(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    # æ£€æŸ¥ admin æƒé™
    if current_user.role != UserRole.ADMIN:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Admin access required"
        )
    users = db.query(User).all()
    return [UserResponse.model_validate(user) for user in users]

@app.get(f"{API_PREFIX}/admin/users/{{user_id}}", response_model=UserResponse)
async def get_user(
    user_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    # æ£€æŸ¥ admin æƒé™
    if current_user.role != UserRole.ADMIN:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Admin access required"
        )
    user = db.query(User).filter(User.id == user_id).first()
    if not user:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="User not found"
        )
    return UserResponse.model_validate(user)

@app.post(f"{API_PREFIX}/admin/users", response_model=UserResponse)
async def create_user(
    user_data: UserCreate,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    # æ£€æŸ¥ admin æƒé™
    if current_user.role != UserRole.ADMIN:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Admin access required"
        )

    # Check if username already exists
    existing_user = get_user_by_username(db, user_data.username)
    if existing_user:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Username already registered"
        )

    # Create user
    hashed_password = hash_password(user_data.password)
    db_user = User(
        username=user_data.username,
        password_hash=hashed_password,
        role=user_data.role
    )
    db.add(db_user)
    db.commit()
    db.refresh(db_user)

    return UserResponse.model_validate(db_user)

@app.put(f"{API_PREFIX}/admin/users/{{user_id}}", response_model=UserResponse)
async def update_user(
    user_id: str,
    user_data: UserUpdate,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    # æ£€æŸ¥ admin æƒé™
    if current_user.role != UserRole.ADMIN:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Admin access required"
        )

    user = db.query(User).filter(User.id == user_id).first()
    if not user:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="User not found"
        )

    # Check if username already exists for different user
    if user_data.username and user_data.username != user.username:
        existing_user = get_user_by_username(db, user_data.username)
        if existing_user:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Username already registered"
            )

    # Update user fields
    if user_data.username:
        user.username = user_data.username
    if user_data.role:
        user.role = user_data.role

    db.commit()
    db.refresh(user)
    return UserResponse.model_validate(user)

@app.delete(f"{API_PREFIX}/admin/users/{{user_id}}")
async def delete_user(
    user_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    # æ£€æŸ¥ admin æƒé™
    if current_user.role != UserRole.ADMIN:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Admin access required"
        )

    user = db.query(User).filter(User.id == user_id).first()
    if not user:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="User not found"
        )

    db.delete(user)
    db.commit()
    return {"message": "User deleted successfully"}

# Session management
@app.get(f"{API_PREFIX}/sessions", response_model=List[SessionResponse])
async def get_sessions(user_id: str, db: Session = Depends(get_db)):
    sessions = db.query(Session).filter(Session.user_id == user_id).all()
    return [SessionResponse.from_orm(session) for session in sessions]

@app.post(f"{API_PREFIX}/sessions", response_model=SessionResponse)
async def create_session(session_data: SessionCreate, db: Session = Depends(get_db)):
    db_session = Session(
        title=session_data.title,
        user_id=session_data.user_id,
        agent_id=session_data.agent_id  # æ–°å¢ï¼šä¿å­˜ agent_id
    )
    db.add(db_session)
    db.commit()
    db.refresh(db_session)
    return SessionResponse.from_orm(db_session)

@app.get(f"{API_PREFIX}/sessions/{{session_id}}/messages", response_model=List[MessageResponse])
async def get_session_messages(session_id: str, current_user: User = Depends(get_current_user), db: Session = Depends(get_db)):
    # éªŒè¯ä¼šè¯æ˜¯å¦å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    session = db.query(Session).filter(
        Session.id == session_id,
        Session.user_id == current_user.id  # æ·»åŠ ç”¨æˆ·æ‰€æœ‰æƒéªŒè¯
    ).first()

    if not session:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Session not found"
        )

    messages = db.query(Message).filter(Message.session_id == session_id).order_by(Message.timestamp.asc(), Message.id.asc()).all()
    return [MessageResponse.from_orm(message) for message in messages]

@app.post(f"{API_PREFIX}/sessions/{{session_id}}/messages")
async def save_messages(session_id: str, message_data: MessageCreate, current_user: User = Depends(get_current_user), db: Session = Depends(get_db)):
    # éªŒè¯ä¼šè¯æ˜¯å¦å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    session = db.query(Session).filter(
        Session.id == session_id,
        Session.user_id == current_user.id  # æ·»åŠ ç”¨æˆ·æ‰€æœ‰æƒéªŒè¯
    ).first()

    if not session:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Session not found"
        )

    # Save or update messages with deduplication by ID
    for msg in message_data.messages:
        msg_id = msg.get('id')
        if not msg_id:
            continue  # Skip messages without ID

        # Check if message already exists
        existing = db.query(Message).filter(Message.id == msg_id).first()

        if existing:
            # Update existing message content
            existing.content = msg['content']
            # Update timestamp if provided
            if 'timestamp' in msg:
                existing.timestamp = datetime.fromisoformat(msg['timestamp'].replace('Z', '+00:00'))
        else:
            # Create new message
            timestamp = datetime.utcnow()
            if 'timestamp' in msg:
                try:
                    timestamp = datetime.fromisoformat(msg['timestamp'].replace('Z', '+00:00'))
                except:
                    pass  # Fallback to current time

            db_message = Message(
                id=msg_id,
                session_id=session_id,
                role=msg['role'],
                content=msg['content'],
                timestamp=timestamp
            )
            db.add(db_message)

    db.commit()
    return {"message": "Messages saved successfully"}

@app.delete(f"{API_PREFIX}/sessions/{{session_id}}")
async def delete_session(session_id: str, current_user: User = Depends(get_current_user), db: Session = Depends(get_db)):
    # éªŒè¯ä¼šè¯æ˜¯å¦å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    session = db.query(Session).filter(
        Session.id == session_id,
        Session.user_id == current_user.id  # æ·»åŠ ç”¨æˆ·æ‰€æœ‰æƒéªŒè¯
    ).first()

    if not session:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Session not found"
        )

    # è·å–ä¼šè¯çš„æ‰€æœ‰æ¶ˆæ¯ ID
    messages = db.query(Message).filter(Message.session_id == session_id).all()
    message_ids = [msg.id for msg in messages]

    # å…ˆåˆ é™¤è¿™äº›æ¶ˆæ¯çš„æ”¶è—è®°å½•ï¼ˆç”±äºå¤–é”®çº¦æŸï¼‰
    if message_ids:
        db.query(MessageFavorite).filter(MessageFavorite.message_id.in_(message_ids)).delete(synchronize_session=False)

    # åˆ é™¤æ‰€æœ‰æ¶ˆæ¯
    db.query(Message).filter(Message.session_id == session_id).delete()

    # åˆ é™¤ä¼šè¯
    session = db.query(Session).filter(Session.id == session_id).first()
    if not session:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Session not found"
        )

    db.delete(session)
    db.commit()
    return {"message": "Session deleted successfully"}

# IAS API proxy - forwards requests to MockServer
@app.post(f"{API_PREFIX}/lmp-cloud-ias-server/api/llm/chat/completions/V2")
async def ias_proxy(request: dict, db: Session = Depends(get_db)):
    """
    Proxy request to configured LLM model API
    Supports dynamic routing based on model selection
    """
    # Get model name from request
    model_name = request.get("model", "")
    if not model_name:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Model name is required"
        )

    # Get model configuration from database
    model = get_llm_model_by_name(db, model_name)

    if not model or not model.is_active:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Model '{model_name}' not found or not active"
        )

    # Get API key (æ˜æ–‡å­˜å‚¨)
    api_key = model.api_key

    # Prepare headers based on model type
    headers = _prepare_model_headers(model, api_key, request)

    # Use model's API URL
    api_url = model.api_url

    # Get streaming flag
    is_stream = request.get("stream", True)

    # Forward request to configured model API
    client = httpx.AsyncClient(timeout=120.0)

    async def forward_stream():
        """Forward SSE stream from model API to Frontend"""
        try:
            async with client.stream('POST',
                api_url,
                json=request,
                headers=headers,
                follow_redirects=True
            ) as model_response:
                if model_response.status_code != 200:
                    logger.error(f"[Model Proxy] {model.display_name} returned {model_response.status_code}")
                    error_detail = await model_response.aread()
                    raise HTTPException(
                        status_code=model_response.status_code,
                        detail=f"Model API error: {error_detail.decode()}"
                    )

                async for chunk in model_response.aiter_bytes():
                    yield chunk
        except HTTPException:
            raise
        except httpx.RequestError as e:
            logger.error(f"[Model Proxy] Connection error to {model.display_name}: {e}")
            raise HTTPException(
                status_code=503,
                detail=f"Failed to connect to model API: {str(e)}"
            )
        except Exception as e:
            logger.error(f"[Model Proxy] Stream error: {e}")
            raise
        finally:
            await client.aclose()

    return StreamingResponse(
        forward_stream(),
        media_type="text/event-stream;charset=utf-8",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
            "Access-Control-Allow-Origin": "*"
        }
    )

def _prepare_model_headers(model: LLMModel, api_key: str, request: dict) -> dict:
    """Prepare headers based on model type"""
    headers = {
        "Content-Type": "application/json",
        "Accept": "text/event-stream"
    }

    if model.model_type == LLMModelType.OPENAI:
        headers["Authorization"] = f"Bearer {api_key}"
    elif model.model_type == LLMModelType.ANTHROPIC:
        headers["x-api-key"] = api_key
        headers["anthropic-version"] = model.api_version or "2023-06-01"
    elif model.model_type == LLMModelType.IAS:
        # For IAS type, use the original authorization from request if available
        auth_header = request.get("authorization", "")
        if auth_header and auth_header.startswith("Bearer "):
            headers["Authorization"] = auth_header
        else:
            # Fallback to using API key as app key
            headers["Authorization"] = f"Bearer {api_key}"
        headers["X-APP-KEY"] = api_key
    else:  # CUSTOM
        # Use custom headers if configured
        headers["Authorization"] = f"Bearer {api_key}"
        if model.custom_headers:
            headers.update(model.custom_headers)

    return headers

# Favorite endpoints
@app.post(f"{API_PREFIX}/messages/{{message_id}}/favorite", response_model=dict)
async def add_favorite(
    message_id: str,
    favorite_data: FavoriteCreate,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """æ”¶è—æ¶ˆæ¯"""
    # éªŒè¯æ¶ˆæ¯å­˜åœ¨
    message = db.query(Message).filter(Message.id == message_id).first()
    if not message:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Message not found"
        )

    # æ£€æŸ¥æ˜¯å¦å·²æ”¶è—
    existing_favorite = db.query(MessageFavorite).filter(
        MessageFavorite.user_id == current_user.id,
        MessageFavorite.message_id == message_id
    ).first()
    if existing_favorite:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Message already favorited"
        )

    # åˆ›å»ºæ”¶è—
    favorite = MessageFavorite(
        user_id=current_user.id,
        message_id=message_id,
        session_id=message.session_id,
        note=favorite_data.note
    )
    db.add(favorite)
    db.commit()
    db.refresh(favorite)

    return {
        "id": favorite.id,
        "messageId": message_id,
        "createdAt": favorite.created_at.isoformat()
    }

@app.delete(f"{API_PREFIX}/messages/{{message_id}}/favorite")
async def remove_favorite(
    message_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """å–æ¶ˆæ”¶è—æ¶ˆæ¯"""
    # æŸ¥æ‰¾æ”¶è—
    favorite = db.query(MessageFavorite).filter(
        MessageFavorite.user_id == current_user.id,
        MessageFavorite.message_id == message_id
    ).first()
    if not favorite:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Favorite not found"
        )

    # åˆ é™¤æ”¶è—
    db.delete(favorite)
    db.commit()

    return {"message": "å–æ¶ˆæ”¶è—æˆåŠŸ"}

@app.get(f"{API_PREFIX}/favorites", response_model=dict)
async def get_favorites(
    current_user: User = Depends(get_current_user),
    limit: int = 20,
    offset: int = 0,
    db: Session = Depends(get_db)
):
    """è·å–æ”¶è—åˆ—è¡¨"""
    # æŸ¥è¯¢æ”¶è—
    query = db.query(MessageFavorite).filter(
        MessageFavorite.user_id == current_user.id
    ).order_by(MessageFavorite.created_at.desc())

    total = query.count()
    favorites = query.limit(limit).offset(offset).all()

    # æ„å»ºå“åº”
    favorite_responses = []
    for fav in favorites:
        # è·å–å…³è”çš„æ¶ˆæ¯å’Œä¼šè¯
        message = db.query(Message).filter(Message.id == fav.message_id).first()
        session = db.query(Session).filter(Session.id == fav.session_id).first()

        if message and session:
            favorite_responses.append({
                "id": fav.id,
                "message": {
                    "id": message.id,
                    "role": message.role,
                    "content": message.content,
                    "timestamp": message.timestamp
                },
                "session": {
                    "id": session.id,
                    "title": session.title,
                    "last_updated": session.last_updated,
                    "user_id": session.user_id
                },
                "note": fav.note,
                "createdAt": fav.created_at
            })

    return {
        "favorites": favorite_responses,
        "total": total
    }

@app.get(f"{API_PREFIX}/messages/{{message_id}}/favorite-status", response_model=dict)
async def get_favorite_status(
    message_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """æ£€æŸ¥æ¶ˆæ¯æ”¶è—çŠ¶æ€"""
    # æŸ¥æ‰¾æ”¶è—
    favorite = db.query(MessageFavorite).filter(
        MessageFavorite.user_id == current_user.id,
        MessageFavorite.message_id == message_id
    ).first()

    return {
        "is_favorited": favorite is not None,
        "favorite_id": favorite.id if favorite else None
    }

# Model management endpoints
@app.get(f"{API_PREFIX}/models/active", response_model=dict)
async def get_active_models(
    db: Session = Depends(get_db)
):
    """è·å–æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹ï¼ˆå…¬å¼€ï¼‰"""
    models = get_active_llm_models(db)

    # æ„å»ºå“åº”ï¼Œä¸è¿”å› API Key
    model_responses = []
    for m in models:
        model_responses.append({
            "id": m.id,
            "name": m.name,
            "display_name": m.display_name,
            "model_type": m.model_type.value,
            "api_url": m.api_url,
            "api_version": m.api_version,
            "description": m.description,
            "is_active": m.is_active,
            "max_tokens": m.max_tokens,
            "temperature": m.temperature / 100.0,  # è½¬æ¢å›æµ®ç‚¹æ•°
            "stream_supported": m.stream_supported,
            "created_at": m.created_at.isoformat()
        })

    return {
        "models": model_responses,
        "total": len(model_responses)
    }

@app.get(f"{API_PREFIX}/admin/models", response_model=dict)
async def list_models(
    skip: int = 0,
    limit: int = 100,
    current_user: User = Depends(require_admin),
    db: Session = Depends(get_db)
):
    """åˆ—å‡ºæ‰€æœ‰æ¨¡å‹ï¼ˆç®¡ç†å‘˜ï¼‰- åŒ…å« API Key"""
    models = list_llm_models(db, skip, limit)

    model_responses = []
    for m in models:
        model_responses.append({
            "id": m.id,
            "name": m.name,
            "display_name": m.display_name,
            "model_type": m.model_type.value,
            "api_url": m.api_url,
            "api_key": m.api_key,  # è¿”å› API Key ç»™ç®¡ç†å‘˜
            "api_version": m.api_version,
            "description": m.description,
            "is_active": m.is_active,
            "max_tokens": m.max_tokens,
            "temperature": m.temperature / 100.0,
            "stream_supported": m.stream_supported,
            "created_at": m.created_at.isoformat()
        })

    return {
        "models": model_responses,
        "total": len(model_responses)
    }

@app.get(f"{API_PREFIX}/admin/models/{{model_id}}", response_model=dict)
async def get_model_detail(
    model_id: str,
    current_user: User = Depends(require_admin),
    db: Session = Depends(get_db)
):
    """è·å–ç‰¹å®šæ¨¡å‹è¯¦æƒ…ï¼ˆç®¡ç†å‘˜ï¼‰- åŒ…å« API Key"""
    model = get_llm_model(db, model_id)
    if not model:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Model not found"
        )

    return {
        "id": model.id,
        "name": model.name,
        "display_name": model.display_name,
        "model_type": model.model_type.value,
        "api_url": model.api_url,
        "api_key": model.api_key,  # è¿”å› API Key ç»™ç®¡ç†å‘˜
        "api_version": model.api_version,
        "description": model.description,
        "is_active": model.is_active,
        "max_tokens": model.max_tokens,
        "temperature": model.temperature / 100.0,
        "stream_supported": model.stream_supported,
        "created_at": model.created_at.isoformat()
    }

@app.post(f"{API_PREFIX}/admin/models", response_model=dict)
async def create_model(
    model_data: LLMModelCreate,
    current_user: User = Depends(require_admin),
    db: Session = Depends(get_db)
):
    """åˆ›å»ºæ–°æ¨¡å‹ï¼ˆç®¡ç†å‘˜ï¼‰"""
    try:
        model = create_llm_model(db, model_data, current_user.id)
        return {
            "id": model.id,
            "name": model.name,
            "display_name": model.display_name,
            "model_type": model.model_type.value,
            "api_url": model.api_url,
            "api_key": model.api_key,
            "is_active": model.is_active,
            "created_at": model.created_at.isoformat()
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to create model: {str(e)}"
        )

@app.put(f"{API_PREFIX}/admin/models/{{model_id}}", response_model=dict)
async def update_model(
    model_id: str,
    model_data: LLMModelUpdate,
    current_user: User = Depends(require_admin),
    db: Session = Depends(get_db)
):
    """æ›´æ–°æ¨¡å‹ï¼ˆç®¡ç†å‘˜ï¼‰"""
    try:
        model = update_llm_model(db, model_id, model_data)
        if not model:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Model not found"
            )
        return {
            "id": model.id,
            "name": model.name,
            "display_name": model.display_name,
            "model_type": model.model_type.value,
            "api_url": model.api_url,
            "api_key": model.api_key,
            "is_active": model.is_active,
            "updated_at": model.updated_at.isoformat()
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to update model: {str(e)}"
        )

@app.delete(f"{API_PREFIX}/admin/models/{{model_id}}")
async def delete_model(
    model_id: str,
    current_user: User = Depends(require_admin),
    db: Session = Depends(get_db)
):
    """åˆ é™¤æ¨¡å‹ï¼ˆç®¡ç†å‘˜ï¼‰"""
    try:
        success = delete_llm_model(db, model_id)
        if not success:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Model not found"
            )
        return {"message": "Model deleted successfully"}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to delete model: {str(e)}"
        )

# ==================== Document Processing Functions ====================

# Global RAG processor instance (lazy loading)
_document_processor: Optional[DocumentProcessor] = None

def get_document_processor() -> DocumentProcessor:
    """è·å–æ–‡æ¡£å¤„ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _document_processor
    if _document_processor is None:
        _document_processor = DocumentProcessor()
    return _document_processor

async def process_document_background(
    doc_id: str,
    file_path: str,
    kb_id: str,
    user_id: str,
    max_retries: int = 3
):
    """
    åå°å¤„ç†æ–‡æ¡£ï¼šè§£æã€åˆ‡ç‰‡ã€å‘é‡åŒ–ã€å­˜å‚¨åˆ° ChromaDBï¼ˆæ”¹è¿›ç‰ˆï¼‰

    Args:
        doc_id: æ–‡æ¡£ ID
        file_path: æ–‡ä»¶è·¯å¾„
        kb_id: çŸ¥è¯†åº“ ID
        user_id: ç”¨æˆ· ID
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤3æ¬¡ï¼‰

    æ”¹è¿›ï¼š
    - æ·»åŠ é‡è¯•æœºåˆ¶
    - è¯¦ç»†çš„æ—¥å¿—è®°å½•
    - æ›´å¥½çš„é”™è¯¯å¤„ç†
    """
    processor = get_document_processor()

    # é‡è¯•å¾ªç¯
    for attempt in range(1, max_retries + 1):
        db_session = None
        try:
            logger.info(f"{'='*60}")
            logger.info(f"[æ–‡æ¡£å¤„ç†] å°è¯• {attempt}/{max_retries}: å¤„ç†æ–‡æ¡£ {doc_id}")
            logger.info(f"  æ–‡ä»¶è·¯å¾„: {file_path}")
            logger.info(f"  çŸ¥è¯†åº“ID: {kb_id}")
            logger.info(f"  ç”¨æˆ·ID: {user_id}")

            # åˆ›å»ºæ–°çš„æ•°æ®åº“ä¼šè¯
            db_session = SessionLocal()

            # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_path):
                logger.error(f"  âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                doc = db_session.query(Document).filter(Document.id == doc_id).first()
                if doc:
                    doc.upload_status = "error"
                    doc.error_message = f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                    db_session.commit()
                return

            file_size = os.path.getsize(file_path)
            logger.info(f"  âœ… æ–‡ä»¶å­˜åœ¨: {file_size} å­—èŠ‚")

            # 2. æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
            doc = db_session.query(Document).filter(Document.id == doc_id).first()
            if not doc:
                logger.error(f"  âŒ æ–‡æ¡£è®°å½•ä¸å­˜åœ¨: {doc_id}")
                return

            doc.upload_status = "processing"
            db_session.commit()
            logger.info(f"  âœ… çŠ¶æ€å·²æ›´æ–°: processing")

            # 3. è°ƒç”¨æ–‡æ¡£å¤„ç†å™¨
            logger.info(f"  ğŸ”„ å¼€å§‹åˆ†å—å’Œå‘é‡åŒ–...")
            result = await processor.process_document(
                file_path=file_path,
                knowledge_base_id=kb_id,
                user_id=user_id,
                filename=Path(file_path).name,
                document_id=doc_id
            )

            logger.info(f"  âœ… å¤„ç†å®Œæˆ: {result}")

            # 4. æ›´æ–°æ•°æ®åº“çŠ¶æ€ - ç®€åŒ–é€»è¾‘
            if result.get("status") == "completed":
                chunk_count = result.get("chunk_count", 0)
            elif isinstance(result, list):
                chunk_count = len(result)
            else:
                chunk_count = 0

            doc.upload_status = "completed"
            doc.chunk_count = chunk_count
            doc.processed_at = func.now()
            doc.error_message = None
            db_session.commit()

            logger.info(f"{'='*60}")
            logger.info(f"âœ… [æ–‡æ¡£å¤„ç†] æ–‡æ¡£ {doc_id} å¤„ç†å®Œæˆ")
            logger.info(f"   Chunks: {chunk_count}")
            logger.info(f"{'='*60}")

            # âœ… ä¿®å¤ï¼šæˆåŠŸåæ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    logger.info(f"âœ… [æ–‡æ¡£å¤„ç†] å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {file_path}")
                except Exception as cleanup_error:
                    logger.warning(f"âš ï¸  [æ–‡æ¡£å¤„ç†] æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {cleanup_error}")

            # æˆåŠŸåé€€å‡ºé‡è¯•å¾ªç¯
            return

        except Exception as e:
            logger.error(f"  âŒ å°è¯• {attempt} å¤±è´¥: {e}", exc_info=True)

            # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥åï¼Œæ›´æ–°ä¸ºé”™è¯¯çŠ¶æ€
            if attempt == max_retries:
                logger.error(f"{'='*60}")
                logger.error(f"âŒ [æ–‡æ¡£å¤„ç†] æ–‡æ¡£ {doc_id} å¤„ç†å¤±è´¥ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰")
                logger.error(f"   é”™è¯¯: {e}")
                logger.error(f"{'='*60}")

                if db_session:
                    try:
                        doc = db_session.query(Document).filter(Document.id == doc_id).first()
                        if doc:
                            doc.upload_status = "error"
                            doc.error_message = f"å¤„ç†å¤±è´¥ï¼ˆé‡è¯•{max_retries}æ¬¡åï¼‰: {str(e)}"
                            db_session.commit()
                    except Exception as commit_error:
                        logger.error(f"  âŒ æ›´æ–°é”™è¯¯çŠ¶æ€å¤±è´¥: {commit_error}")
            else:
                # è¿˜æœ‰é‡è¯•æœºä¼šï¼Œç»§ç»­å¾ªç¯
                wait_time = attempt * 2
                logger.warning(f"  â³ {wait_time}ç§’åé‡è¯•...")
                await asyncio.sleep(wait_time)

        finally:
            # âœ… ä¿®å¤ï¼šç¡®ä¿åœ¨ä»»ä½•æƒ…å†µä¸‹éƒ½æ¸…ç†æ•°æ®åº“è¿æ¥å’Œä¸´æ—¶æ–‡ä»¶
            if db_session:
                try:
                    db_session.close()
                except:
                    pass

            # âœ… ä¿®å¤ï¼šç¡®ä¿ä¸´æ—¶æ–‡ä»¶è¢«æ¸…ç†ï¼ˆä»…åœ¨æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥åï¼‰
            if attempt == max_retries and os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    logger.info(f"âœ… [æ–‡æ¡£å¤„ç†] å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆé‡è¯•å¤±è´¥åï¼‰: {file_path}")
                except Exception as cleanup_error:
                    logger.warning(f"âš ï¸  [æ–‡æ¡£å¤„ç†] æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {cleanup_error}")

# ==================== Knowledge Base APIs ====================

@app.get(API_PREFIX + "/knowledge/groups", response_model=List[KnowledgeGroupResponse])
async def get_knowledge_groups(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """è·å–å½“å‰ç”¨æˆ·çš„çŸ¥è¯†åº“åˆ†ç»„åˆ—è¡¨"""
    groups = db.query(KnowledgeGroup).filter(
        KnowledgeGroup.user_id == current_user.id
    ).order_by(KnowledgeGroup.created_at.desc()).all()
    return [KnowledgeGroupResponse.from_orm(g) for g in groups]

@app.post(API_PREFIX + "/knowledge/groups", response_model=KnowledgeGroupResponse)
async def create_knowledge_group(
    group_data: KnowledgeGroupCreate,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """åˆ›å»ºçŸ¥è¯†åº“åˆ†ç»„"""
    # æ£€æŸ¥åç§°æ˜¯å¦é‡å¤
    existing = db.query(KnowledgeGroup).filter(
        KnowledgeGroup.user_id == current_user.id,
        KnowledgeGroup.name == group_data.name
    ).first()
    if existing:
        raise HTTPException(status_code=400, detail="åˆ†ç»„åç§°å·²å­˜åœ¨")

    group = KnowledgeGroup(
        name=group_data.name,
        description=group_data.description,
        user_id=current_user.id
    )
    db.add(group)
    db.commit()
    db.refresh(group)
    return KnowledgeGroupResponse.from_orm(group)

@app.delete(API_PREFIX + "/knowledge/groups/{group_id}")
async def delete_knowledge_group(
    group_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """åˆ é™¤çŸ¥è¯†åº“åˆ†ç»„ï¼ˆåŠå…¶æ‰€æœ‰çŸ¥è¯†åº“ï¼‰"""
    group = db.query(KnowledgeGroup).filter(
        KnowledgeGroup.id == group_id,
        KnowledgeGroup.user_id == current_user.id
    ).first()
    if not group:
        raise HTTPException(status_code=404, detail="åˆ†ç»„ä¸å­˜åœ¨")

    db.delete(group)
    db.commit()
    return {"message": "åˆ†ç»„å·²åˆ é™¤"}

@app.get(API_PREFIX + "/knowledge/bases", response_model=List[KnowledgeBaseResponse])
async def get_knowledge_bases(
    group_id: Optional[str] = None,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """è·å–çŸ¥è¯†åº“åˆ—è¡¨"""
    query = db.query(KnowledgeBase).filter(
        KnowledgeBase.user_id == current_user.id
    )

    if group_id:
        query = query.filter(KnowledgeBase.group_id == group_id)

    bases = query.order_by(KnowledgeBase.created_at.desc()).all()

    # æ·»åŠ æ–‡æ¡£è®¡æ•°
    result = []
    for base in bases:
        base_dict = KnowledgeBaseResponse.from_orm(base).dict()
        doc_count = db.query(Document).filter(
            Document.knowledge_base_id == base.id,
            Document.upload_status == "completed"
        ).count()
        base_dict["document_count"] = doc_count
        result.append(KnowledgeBaseResponse(**base_dict))

    return result

@app.post(API_PREFIX + "/knowledge/bases", response_model=KnowledgeBaseResponse)
async def create_knowledge_base(
    base_data: KnowledgeBaseCreate,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """åˆ›å»ºçŸ¥è¯†åº“"""
    # å¦‚æœæŒ‡å®šäº† group_idï¼ŒéªŒè¯å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    if base_data.group_id:
        group = db.query(KnowledgeGroup).filter(
            KnowledgeGroup.id == base_data.group_id,
            KnowledgeGroup.user_id == current_user.id
        ).first()
        if not group:
            raise HTTPException(status_code=404, detail="åˆ†ç»„ä¸å­˜åœ¨")

    # æ£€æŸ¥åç§°æ˜¯å¦é‡å¤ï¼ˆåœ¨åŒä¸€åˆ†ç»„ä¸‹æˆ–å…¨å±€ï¼‰
    existing_query = db.query(KnowledgeBase).filter(
        KnowledgeBase.user_id == current_user.id,
        KnowledgeBase.name == base_data.name
    )
    # å¦‚æœæŒ‡å®šäº†åˆ†ç»„ï¼Œåªåœ¨åŒä¸€åˆ†ç»„å†…æ£€æŸ¥é‡å¤
    if base_data.group_id:
        existing_query = existing_query.filter(KnowledgeBase.group_id == base_data.group_id)
    else:
        # å¦‚æœæ²¡æœ‰åˆ†ç»„ï¼Œæ£€æŸ¥å…¶ä»–æ— åˆ†ç»„çš„çŸ¥è¯†åº“æ˜¯å¦æœ‰é‡å
        existing_query = existing_query.filter(KnowledgeBase.group_id == None)

    existing = existing_query.first()
    if existing:
        raise HTTPException(status_code=400, detail="çŸ¥è¯†åº“åç§°å·²å­˜åœ¨")

    base = KnowledgeBase(
        group_id=base_data.group_id,  # å¯ä»¥ä¸º None
        user_id=current_user.id,
        name=base_data.name,
        description=base_data.description,
        embedding_model=base_data.embedding_model,
        chunk_size=base_data.chunk_size,
        chunk_overlap=base_data.chunk_overlap
    )
    db.add(base)
    db.commit()
    db.refresh(base)
    return KnowledgeBaseResponse.from_orm(base)

@app.get(API_PREFIX + "/knowledge/bases/{kb_id}", response_model=KnowledgeBaseResponse)
async def get_knowledge_base(
    kb_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """è·å–çŸ¥è¯†åº“è¯¦æƒ…"""
    base = db.query(KnowledgeBase).filter(
        KnowledgeBase.id == kb_id,
        KnowledgeBase.user_id == current_user.id
    ).first()
    if not base:
        raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨")

    response = KnowledgeBaseResponse.from_orm(base).dict()
    doc_count = db.query(Document).filter(
        Document.knowledge_base_id == base.id,
        Document.upload_status == "completed"
    ).count()
    response["document_count"] = doc_count
    return KnowledgeBaseResponse(**response)

@app.delete(API_PREFIX + "/knowledge/bases/{kb_id}")
async def delete_knowledge_base(
    kb_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """åˆ é™¤çŸ¥è¯†åº“ï¼ˆåŠå…¶æ‰€æœ‰æ–‡æ¡£ï¼‰"""
    base = db.query(KnowledgeBase).filter(
        KnowledgeBase.id == kb_id,
        KnowledgeBase.user_id == current_user.id
    ).first()
    if not base:
        raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨")

    # å…ˆæ¸…ç† ChromaDB å‘é‡
    try:
        processor = DocumentProcessor(rag_config)
        await processor.delete_knowledge_base(kb_id)
        logger.info(f"å·²æ¸…ç†çŸ¥è¯†åº“ {kb_id} çš„ ChromaDB å‘é‡")
    except Exception as e:
        logger.error(f"æ¸…ç† ChromaDB å‘é‡å¤±è´¥: {e}")
        # ç»§ç»­åˆ é™¤ MySQL è®°å½•ï¼Œä¸é˜»æ­¢æ“ä½œ

    # å†åˆ é™¤ MySQL è®°å½•
    db.delete(base)
    db.commit()
    return {"message": "çŸ¥è¯†åº“å·²åˆ é™¤"}

@app.get(API_PREFIX + "/knowledge/bases/{kb_id}/documents", response_model=List[DocumentResponse])
async def get_documents(
    kb_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """è·å–çŸ¥è¯†åº“çš„æ–‡æ¡£åˆ—è¡¨"""
    # éªŒè¯çŸ¥è¯†åº“å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    base = db.query(KnowledgeBase).filter(
        KnowledgeBase.id == kb_id,
        KnowledgeBase.user_id == current_user.id
    ).first()
    if not base:
        raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨")

    docs = db.query(Document).filter(
        Document.knowledge_base_id == kb_id
    ).order_by(Document.created_at.desc()).all()
    return [DocumentResponse.from_orm(d) for d in docs]

@app.get(API_PREFIX + "/knowledge/bases/{kb_id}/documents/{doc_id}", response_model=DocumentResponse)
async def get_document(
    kb_id: str,
    doc_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """è·å–æ–‡æ¡£è¯¦æƒ…"""
    # éªŒè¯çŸ¥è¯†åº“å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    base = db.query(KnowledgeBase).filter(
        KnowledgeBase.id == kb_id,
        KnowledgeBase.user_id == current_user.id
    ).first()
    if not base:
        raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨")

    doc = db.query(Document).filter(
        Document.id == doc_id,
        Document.knowledge_base_id == kb_id
    ).first()
    if not doc:
        raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")

    return DocumentResponse.from_orm(doc)

@app.get(API_PREFIX + "/knowledge/bases/{kb_id}/documents/{doc_id}/chunks")
async def get_document_chunks(
    kb_id: str,
    doc_id: str,
    offset: int = 0,
    limit: Optional[int] = None,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """è·å–æ–‡æ¡£åˆ‡ç‰‡è¯¦æƒ…ï¼ˆæ”¯æŒåˆ†é¡µï¼‰"""
    # éªŒè¯çŸ¥è¯†åº“å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    base = db.query(KnowledgeBase).filter(
        KnowledgeBase.id == kb_id,
        KnowledgeBase.user_id == current_user.id
    ).first()
    if not base:
        raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨")

    # éªŒè¯æ–‡æ¡£å­˜åœ¨
    doc = db.query(Document).filter(
        Document.id == doc_id,
        Document.knowledge_base_id == kb_id
    ).first()
    if not doc:
        raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")

    # ä» ChromaDB è·å–åˆ‡ç‰‡
    try:
        rag_config = get_rag_config()
        collection = rag_config.get_or_create_collection(KNOWLEDGE_COLLECTION)

        # æŸ¥è¯¢è¯¥æ–‡æ¡£çš„æ‰€æœ‰åˆ‡ç‰‡
        results = collection.get(
            where={"document_id": doc_id}
        )

        chunks = []
        for i, (text, metadata) in enumerate(zip(results.get('documents', []), results.get('metadatas', []))):
            chunks.append({
                "id": f"{doc_id}_chunk_{i}",
                "chunk_index": metadata.get("chunk_index", i),
                "content": text,
                "metadata": metadata
            })

        # åº”ç”¨åˆ†é¡µ
        total_count = len(chunks)
        start_idx = offset
        end_idx = offset + limit if limit else len(chunks)

        # ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
        if start_idx >= total_count:
            paginated_chunks = []
        else:
            paginated_chunks = chunks[start_idx:end_idx]

        # âœ… è¿”å›å¯¹è±¡è€Œä¸æ˜¯æ•°ç»„ï¼Œä¸ app/rag/router.py ä¿æŒä¸€è‡´
        return {
            "document_id": doc_id,
            "filename": doc.filename,
            "chunks": paginated_chunks,
            "total_count": total_count,
            "returned_count": len(paginated_chunks),
            "offset": offset,
            "limit": limit
        }
    except Exception as e:
        logger.error(f"è·å–æ–‡æ¡£åˆ‡ç‰‡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–åˆ‡ç‰‡å¤±è´¥: {str(e)}")


@app.get(API_PREFIX + "/knowledge/search")
async def search_knowledge(
    query: str,
    knowledge_base_ids: Optional[str] = None,  # æ”¹ä¸ºå¯é€‰å‚æ•°
    top_k: int = 5,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """çŸ¥è¯†æ£€ç´¢"""
    if not query:
        raise HTTPException(status_code=400, detail="æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©º")

    # å¯¼å…¥ RAG é…ç½®
    from app.rag.config import get_rag_config
    rag_config = get_rag_config()

    # å¦‚æœæ²¡æœ‰æŒ‡å®šçŸ¥è¯†åº“ï¼Œä½¿ç”¨ç”¨æˆ·çš„æ‰€æœ‰çŸ¥è¯†åº“
    if knowledge_base_ids:
        # è§£æçŸ¥è¯†åº“ ID åˆ—è¡¨
        try:
            kb_ids = knowledge_base_ids.split(',')
        except:
            raise HTTPException(status_code=400, detail="çŸ¥è¯†åº“ ID æ ¼å¼é”™è¯¯")

        # éªŒè¯æ‰€æœ‰çŸ¥è¯†åº“éƒ½å±äºå½“å‰ç”¨æˆ·
        bases = db.query(KnowledgeBase).filter(
            KnowledgeBase.id.in_(kb_ids),
            KnowledgeBase.user_id == current_user.id
        ).all()
        if len(bases) != len(kb_ids):
            raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æŸäº›çŸ¥è¯†åº“")
    else:
        # è·å–ç”¨æˆ·çš„æ‰€æœ‰çŸ¥è¯†åº“
        bases = db.query(KnowledgeBase).filter(
            KnowledgeBase.user_id == current_user.id
        ).all()
        kb_ids = [kb.id for kb in bases]

    # å¦‚æœç”¨æˆ·æ²¡æœ‰ä»»ä½•çŸ¥è¯†åº“ï¼Œè¿”å›ç©ºç»“æœ
    if not kb_ids:
        return {
            "results": [],
            "query": query,
            "total": 0,
            "message": "æš‚æ— å¯æœç´¢çš„çŸ¥è¯†åº“ï¼Œè¯·å…ˆåˆ›å»ºçŸ¥è¯†åº“å¹¶ä¸Šä¼ æ–‡æ¡£"
        }

    try:
        # ä½¿ç”¨ RAGRetriever è¿›è¡Œæœç´¢ï¼ˆæ”¯æŒå¤šçŸ¥è¯†åº“æœç´¢ï¼‰
        from app.rag.retriever import RAGRetriever
        retriever = RAGRetriever(rag_config)

        # æ‰§è¡Œæ£€ç´¢
        search_results = await retriever.search(
            query=query,
            knowledge_base_ids=kb_ids,
            user_id=current_user.id,
            top_k=top_k
        )

        # æ ¼å¼åŒ–ç»“æœ
        formatted_results = []
        for result in search_results:
            formatted_results.append({
                "id": result["id"],
                "content": result["content"],
                "metadata": result["metadata"],
                "similarity": round(result["similarity"], 3),
                "distance": round(result["distance"], 3)
            })

        return {"results": formatted_results, "query": query, "total": len(formatted_results)}
    except Exception as e:
        logger.error(f"çŸ¥è¯†æ£€ç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ£€ç´¢å¤±è´¥: {str(e)}")


@app.delete(API_PREFIX + "/knowledge/bases/{kb_id}/documents/{doc_id}")
async def delete_document(
    kb_id: str,
    doc_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """åˆ é™¤æ–‡æ¡£"""
    # éªŒè¯çŸ¥è¯†åº“å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    base = db.query(KnowledgeBase).filter(
        KnowledgeBase.id == kb_id,
        KnowledgeBase.user_id == current_user.id
    ).first()
    if not base:
        raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨")

    doc = db.query(Document).filter(
        Document.id == doc_id,
        Document.knowledge_base_id == kb_id
    ).first()
    if not doc:
        raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")

    # å…ˆæ¸…ç† ChromaDB å‘é‡
    try:
        processor = DocumentProcessor(rag_config)
        await processor.delete_document(doc_id)
        logger.info(f"å·²æ¸…ç†æ–‡æ¡£ {doc_id} çš„ ChromaDB å‘é‡")
    except Exception as e:
        logger.error(f"æ¸…ç† ChromaDB å‘é‡å¤±è´¥: {e}")
        # ç»§ç»­åˆ é™¤ MySQL è®°å½•ï¼Œä¸é˜»æ­¢æ“ä½œ

    # å†åˆ é™¤ MySQL è®°å½•
    db.delete(doc)
    db.commit()
    return {"message": "æ–‡æ¡£å·²åˆ é™¤"}

@app.post(API_PREFIX + "/knowledge/bases/{kb_id}/documents", response_model=DocumentResponse)
async def upload_document(
    kb_id: str,
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    sync: bool = False,  # æ–°å¢ï¼šæ˜¯å¦åŒæ­¥å¤„ç†
    chunk_size: int = 500,  # æ–°å¢ï¼šåˆ†å—å¤§å°
    chunk_overlap: int = 50,  # æ–°å¢ï¼šåˆ†å—é‡å 
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """
    ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“ï¼ˆæ”¯æŒåŒæ­¥/å¼‚æ­¥å¤„ç†ï¼‰

    æµç¨‹ï¼š
    1. éªŒè¯çŸ¥è¯†åº“æƒé™
    2. ä¿å­˜æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
    3. åˆ›å»ºæ–‡æ¡£è®°å½•ï¼ˆçŠ¶æ€=pendingï¼‰
    4. åŒæ­¥æ¨¡å¼ï¼šç«‹å³å¤„ç†æ–‡æ¡£ï¼›å¼‚æ­¥æ¨¡å¼ï¼šå¯åŠ¨åå°ä»»åŠ¡
    5. è¿”å›å“åº”

    å‚æ•°ï¼š
    - sync: true=åŒæ­¥å¤„ç†ï¼ˆç«‹å³å®Œæˆï¼‰ï¼Œfalse=å¼‚æ­¥å¤„ç†ï¼ˆåå°ä»»åŠ¡ï¼‰
    - chunk_size: æ–‡æœ¬åˆ†å—å¤§å°ï¼ˆé»˜è®¤500å­—ç¬¦ï¼‰
    - chunk_overlap: åˆ†å—é‡å å¤§å°ï¼ˆé»˜è®¤50å­—ç¬¦ï¼‰
    """
    temp_file_path = None
    try:
        # 1. éªŒè¯çŸ¥è¯†åº“å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        kb = db.query(KnowledgeBase).filter(
            KnowledgeBase.id == kb_id,
            KnowledgeBase.user_id == current_user.id
        ).first()

        if not kb:
            raise HTTPException(status_code=404, detail="çŸ¥è¯†åº“ä¸å­˜åœ¨")

        # 2. ä¿å­˜æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        temp_dir = Path("uploads/documents")
        temp_dir.mkdir(parents=True, exist_ok=True)

        file_extension = Path(file.filename).suffix
        temp_file_path = temp_dir / f"{uuid.uuid4()}{file_extension}"

        with open(temp_file_path, "wb") as f:
            content = await file.read()
            f.write(content)

        logger.info(f"[æ–‡æ¡£ä¸Šä¼ ] æ–‡ä»¶å·²ä¿å­˜åˆ°: {temp_file_path} (å¤§å°: {len(content)} å­—èŠ‚)")

        # 3. åˆ›å»ºæ–‡æ¡£è®°å½•ï¼ˆçŠ¶æ€ï¼špendingï¼‰
        document = Document(
            knowledge_base_id=kb_id,
            filename=file.filename,
            file_type=file.content_type or "application/octet-stream",
            file_size=len(content),
            upload_status="pending"
        )
        db.add(document)
        db.commit()
        db.refresh(document)

        logger.info(f"[æ–‡æ¡£ä¸Šä¼ ] æ–‡æ¡£è®°å½•å·²åˆ›å»º: {document.id}")

        # 4. æ ¹æ®syncå‚æ•°é€‰æ‹©å¤„ç†æ–¹å¼
        if sync:
            # åŒæ­¥å¤„ç†æ¨¡å¼ï¼ˆç«‹å³å®Œæˆï¼‰
            logger.info(f"[æ–‡æ¡£ä¸Šä¼ ] ä½¿ç”¨åŒæ­¥å¤„ç†æ¨¡å¼")
            try:
                processor = get_document_processor()

                # ç›´æ¥å¤„ç†æ–‡æ¡£
                result = await processor.process_document(
                    file_path=str(temp_file_path),
                    knowledge_base_id=kb_id,
                    user_id=current_user.id,
                    filename=file.filename,
                    chunk_size=chunk_size,
                    chunk_overlap=chunk_overlap,
                    document_id=document.id
                )

                # âœ… ä¿®å¤ï¼šä» result dict ä¸­æ­£ç¡®è·å– chunk_count
                if result.get("status") == "completed":
                    document.upload_status = "completed"
                    document.chunk_count = result.get("chunk_count", 0)
                    db.commit()
                    logger.info(f"âœ… [æ–‡æ¡£ä¸Šä¼ ] åŒæ­¥å¤„ç†æˆåŠŸ: {result.get('chunk_count', 0)} ä¸ªchunks")
                else:
                    document.upload_status = "error"
                    document.error_message = result.get("error", "æœªçŸ¥é”™è¯¯")
                    db.commit()
                    logger.error(f"âŒ [æ–‡æ¡£ä¸Šä¼ ] åŒæ­¥å¤„ç†å¤±è´¥: {document.error_message}")
                    raise HTTPException(status_code=500, detail=f"æ–‡æ¡£å¤„ç†å¤±è´¥: {document.error_message}")
            except HTTPException:
                raise
            except Exception as e:
                # åŒæ­¥å¤„ç†å¤±è´¥
                document.upload_status = "error"
                document.error_message = str(e)
                db.commit()
                logger.error(f"âŒ [æ–‡æ¡£ä¸Šä¼ ] åŒæ­¥å¤„ç†å¤±è´¥: {e}", exc_info=True)
                raise HTTPException(status_code=500, detail=f"æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}")
            finally:
                # âœ… ä¿®å¤ï¼šåŒæ­¥æ¨¡å¼å®Œæˆåæ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if temp_file_path and os.path.exists(temp_file_path):
                    try:
                        os.remove(temp_file_path)
                        logger.info(f"[æ–‡æ¡£ä¸Šä¼ ] å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_file_path}")
                    except Exception as cleanup_error:
                        logger.warning(f"[æ–‡æ¡£ä¸Šä¼ ] æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {cleanup_error}")
        else:
            # å¼‚æ­¥å¤„ç†æ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            logger.info(f"[æ–‡æ¡£ä¸Šä¼ ] ä½¿ç”¨å¼‚æ­¥å¤„ç†æ¨¡å¼")
            background_tasks.add_task(
                process_document_background,
                document.id,
                str(temp_file_path),
                kb_id,
                current_user.id
            )
            logger.info(f"[æ–‡æ¡£ä¸Šä¼ ] åå°å¤„ç†ä»»åŠ¡å·²å¯åŠ¨: {document.id}")
            # æ³¨æ„ï¼šå¼‚æ­¥æ¨¡å¼ä¸‹ï¼Œä¸´æ—¶æ–‡ä»¶ç”± process_document_background è´Ÿè´£æ¸…ç†

        return document

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[æ–‡æ¡£ä¸Šä¼ ] å¤±è´¥: {e}", exc_info=True)

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_file_path and os.path.exists(temp_file_path):
            os.remove(temp_file_path)

        raise HTTPException(status_code=500, detail=f"æ–‡æ¡£ä¸Šä¼ å¤±è´¥: {str(e)}")

# Health check
@app.get("/health")
async def health_check():
    return {"status": "healthy", "version": "1.0.0"}

# Detailed system health check
@app.get(f"{API_PREFIX}/system/health")
async def system_health_check(current_user: User = Depends(get_current_user)):
    """
    ç³»ç»Ÿå¥åº·æ£€æŸ¥ï¼ˆè¯¦ç»†ç‰ˆï¼‰

    æ£€æŸ¥é¡¹ç›®ï¼š
    - æ•°æ®åº“è¿æ¥
    - ChromaDBè¿æ¥å’ŒcollectionçŠ¶æ€
    - BGEæ¨¡å‹åŠ è½½çŠ¶æ€
    """
    health = {
        "timestamp": datetime.now().isoformat(),
        "status": "healthy",
        "components": {}
    }

    # 1. æ£€æŸ¥æ•°æ®åº“
    try:
        db = SessionLocal()
        db.execute(text("SELECT 1"))
        db.close()
        health["components"]["database"] = {"status": "healthy", "message": "æ•°æ®åº“è¿æ¥æ­£å¸¸"}
    except Exception as e:
        health["components"]["database"] = {"status": "unhealthy", "error": str(e)}
        health["status"] = "degraded"

    # 2. æ£€æŸ¥ChromaDB
    try:
        rag_config = get_rag_config()

        # æ£€æŸ¥è¿æ¥
        if not rag_config.health_check():
            health["components"]["chromadb"] = {"status": "down", "error": "ChromaDBè¿æ¥å¤±è´¥"}
            health["status"] = "unhealthy"
        else:
            # æ£€æŸ¥collectionå¥åº·çŠ¶æ€
            try:
                collection = rag_config.get_or_create_collection(KNOWLEDGE_COLLECTION)
                count = collection.count()
                health["components"]["chromadb"] = {
                    "status": "healthy",
                    "message": "ChromaDBè¿æ¥æ­£å¸¸",
                    "collection": KNOWLEDGE_COLLECTION,
                    "vector_count": count
                }
            except Exception as e:
                health["components"]["chromadb"] = {
                    "status": "degraded",
                    "message": "ChromaDBè¿æ¥æ­£å¸¸ï¼Œä½†collectionæœ‰é—®é¢˜",
                    "error": str(e)
                }
                health["status"] = "degraded"

    except Exception as e:
        health["components"]["chromadb"] = {"status": "down", "error": str(e)}
        health["status"] = "unhealthy"

    # 3. æ£€æŸ¥BGEæ¨¡å‹
    try:
        rag_config = get_rag_config()
        model = rag_config.embedding_model
        dimension = model.get_sentence_embedding_dimension()
        health["components"]["embedding_model"] = {
            "status": "healthy",
            "model_name": rag_config.embedding_model_name,
            "dimension": dimension
        }
    except Exception as e:
        health["components"]["embedding_model"] = {"status": "unhealthy", "error": str(e)}
        health["status"] = "degraded"

    return health

# Root
@app.get("/")
async def root():
    return {"name": APP_NAME, "version": "1.0.0", "docs": "/docs"}

# Create default admin user
def create_default_admin():
    db = SessionLocal()
    try:
        # Check if admin exists
        admin = get_user_by_username(db, "admin")
        if not admin:
            logger.info("Creating default admin user...")
            hashed_password = get_password_hash("pwd123")
            admin = User(
                username="admin",
                password_hash=hashed_password,
                role=UserRole.ADMIN
            )
            db.add(admin)
            db.commit()
            logger.info("Default admin created: admin / admin123")
    except Exception as e:
        logger.error(f"Error creating admin user: {e}")
    finally:
        db.close()

# Create default admin on startup
create_default_admin()

# Startup event: åˆå§‹åŒ–å’Œæ£€æŸ¥ç³»ç»Ÿç»„ä»¶
@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–å’Œå¥åº·æ£€æŸ¥"""
    logger.info("="*60)
    logger.info("ç³»ç»Ÿåˆå§‹åŒ–")
    logger.info("="*60)

    # 1. æ£€æŸ¥æ•°æ®åº“è¿æ¥
    logger.info("1. æ£€æŸ¥æ•°æ®åº“è¿æ¥...")
    try:
        db = SessionLocal()
        db.execute(text("SELECT 1"))
        db.close()
        logger.info("   âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸")
    except Exception as e:
        logger.error(f"   âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")

    # 2. æ£€æŸ¥ChromaDBå¹¶è‡ªåŠ¨ä¿®å¤
    logger.info("2. æ£€æŸ¥ChromaDB...")
    try:
        rag_config = get_rag_config()

        if not rag_config.health_check():
            logger.error("   âŒ ChromaDBè¿æ¥å¤±è´¥")
            logger.error("   è¯·å¯åŠ¨ChromaDB:")
            logger.error("   docker run -d -p 8002:8000 --name bright-chat-chromadb chromadb/chroma:latest")
        else:
            logger.info("   âœ… ChromaDBè¿æ¥æ­£å¸¸")

            # æ£€æŸ¥å¹¶ä¿®å¤knowledge_chunks collection
            logger.info("3. æ£€æŸ¥knowledge_chunks collection...")
            try:
                collection = rag_config.get_or_create_collection(KNOWLEDGE_COLLECTION)
                count = collection.count()
                logger.info(f"   âœ… Collectionå¥åº· ({count} ä¸ªå‘é‡)")
            except Exception as e:
                logger.warning(f"   âš ï¸  Collectionæ£€æŸ¥å¤±è´¥: {e}")
                logger.info("   å°è¯•è‡ªåŠ¨ä¿®å¤...")

                try:
                    # å°è¯•é‡å»ºcollection
                    rag_config.chroma_client.delete_collection(KNOWLEDGE_COLLECTION)
                    rag_config.chroma_client.create_collection(KNOWLEDGE_COLLECTION)
                    logger.info("   âœ… Collectioné‡å»ºæˆåŠŸ")
                except Exception as repair_error:
                    logger.error(f"   âŒ Collectionä¿®å¤å¤±è´¥: {repair_error}")

    except Exception as e:
        logger.error(f"   âŒ ChromaDBåˆå§‹åŒ–å¤±è´¥: {e}")

    # 3. æ£€æŸ¥BGEæ¨¡å‹ï¼ˆå¯é€‰ï¼Œå¤±è´¥ä¸å½±å“å¯åŠ¨ï¼‰
    logger.info("4. æ£€æŸ¥BGEæ¨¡å‹...")
    try:
        # é¢„åŠ è½½æ¨¡å‹ï¼ˆé¦–æ¬¡åŠ è½½ä¼šè¾ƒæ…¢ï¼‰
        rag_config = get_rag_config()
        model = rag_config.embedding_model
        dimension = model.get_sentence_embedding_dimension()
        logger.info(f"   âœ… BGEæ¨¡å‹åŠ è½½æˆåŠŸ (ç»´åº¦: {dimension})")
    except Exception as e:
        logger.warning(f"   âš ï¸  BGEæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        logger.warning("   å‘é‡åŒ–åŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œä½†å…¶ä»–åŠŸèƒ½æ­£å¸¸")

    logger.info("="*60)
    logger.info("ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    logger.info("="*60)

# Shutdown event
@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶çš„æ¸…ç†"""
    logger.info("ç³»ç»Ÿæ­£åœ¨å…³é—­...")
    # è¿™é‡Œå¯ä»¥æ·»åŠ æ¸…ç†é€»è¾‘
    logger.info("ç³»ç»Ÿå·²å…³é—­")

if __name__ == "__main__":
    import uvicorn
    print(f"Starting {APP_NAME}...")
    print(f"Server running on: http://{SERVER_HOST}:{SERVER_PORT}")
    print(f"API Documentation: http://localhost:{SERVER_PORT}/docs")
    uvicorn.run(
        "minimal_api:app",
        host=SERVER_HOST,
        port=SERVER_PORT,
        reload=False,
        log_level="info"
    )